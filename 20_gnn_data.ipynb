{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd371bd9-82c7-44c7-8826-beb0c549974b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modify the file 00_setup.py to define input/output file paths on your system\n",
    "# The information in 00_setup.py will be used across notebooks\n",
    "from importlib.machinery import SourceFileLoader\n",
    "setup = SourceFileLoader(\"setup\", \"./00_setup.py\").load_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7d3f74-1737-4eee-9e6f-06233b68c2b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 20: GNN Data\n",
    "Data for a GNN view of NAICS, where NAICS and NAICS sectors are edges connecting nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6956879-bdba-4750-bbdf-e26ade43c72f",
   "metadata": {},
   "source": [
    "*This script takes about 1 hour on my MacBook Air*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06b80fe-17ee-409a-8f41-ab2427d6f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4278237c-f6ad-4cd9-9144-5b7bb134a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib, pickle\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef27d75-0483-48fb-8018-245bdb9df81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputer object for easy dataset conversion to GNN friendly format\n",
    "from sba_gnn.sba_gnn import sg_imputer \n",
    "from sba_gnn.sba_gnn.sg_imputer import GNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd1aebd2-f102-4fec-b65c-984d64ca4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00354e71-0de3-4eea-9b3c-01d084a1ebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 06:32:57.952022: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-01-17 06:32:57.952059: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-01-17 06:32:57.952073: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-01-17 06:32:57.952295: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-17 06:32:57.952318: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from stellargraph import StellarGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e08909-0395-40e8-b518-11c69da68b36",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c5cf92-35ea-4371-b3e0-04abc85a41dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = pd.read_parquet(Path(setup.temp_path).joinpath('10_DATA_combined_scaled_all.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b1f7125-9a15-4aaf-b49a-3d882e6a37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(setup.temp_path).joinpath('10_DATA_features.pkl'), 'rb') as fin:\n",
    "    imputed_features = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69129e21-dd98-434f-97b7-55bdcb3734ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NoEmp', 'CreateJob', 'LowDoc', 'DisbursementGross', 'new_business', 'urban_flag', 'franchise_flag', 'missingindicator_LowDoc', 'missingindicator_new_business', 'missingindicator_urban_flag']\n"
     ]
    }
   ],
   "source": [
    "num_feat =  [c for c in imputed_features if c != 'NAICS']\n",
    "print(num_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004afdb3-da89-433f-b28b-5e2bb34c5388",
   "metadata": {},
   "source": [
    "## Edge Mapping Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433523f-9b47-49bb-8693-d58a935ba046",
   "metadata": {},
   "source": [
    "There are 2 edge types:\n",
    "  * NAICS connects exact NAICS match edges\n",
    "  * naics_sector - connects same sector edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432ccad-da21-4ecb-a17c-5fff91c94818",
   "metadata": {},
   "source": [
    "There are a very large number of edges.  These will be sampled in the graph but even to load a graph will be too much on home hardware (and likely not really worth it).  So I will pre-sample for each node for both edge types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee8d1e-3a7a-489a-99d1-336108e90b8a",
   "metadata": {},
   "source": [
    "I want to get at least a set number of edges per node (setup.gnn_graph_sample_n), and so I sample accordingly. There may be more than this number of edges per node.  For higher-volume NAICS, the edge count per node will be closer to setup.gnn_graph_sample_n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae69a5a-cf38-4837-8c4a-e1c92555a0b4",
   "metadata": {},
   "source": [
    "The GNN will do sampling also, and so I need the GNN samples to be less than setup.gnn_graph_sample_n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a025da79-6d49-42b3-bf47-b9b4dac19a66",
   "metadata": {},
   "source": [
    "##### Function to create samples for 1 code\n",
    "Returns an edge list containing at least a set number of samples per node.  The list may contain more edges than requested, but will be smaller than the full edge list.  For high-volume code, the number of edges is ~setup.gnn_graph_sample_n, and the total rows is close to (# businesses with the code) * setup.gnn_graph_sample_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf04d638-6a1d-4085-83ff-f5771f71a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_per_code(ser, min_n = setup.gnn_graph_sample_n,\n",
    "                       big_thresh = 500):\n",
    "    \"\"\" Samples edges for each node, returning at least min_n edges for each node,\n",
    "      Inputs:\n",
    "        ser:  Pandas series consisting of node indexes\n",
    "        min_n: Minimum number of edges per node\n",
    "      Value:\n",
    "        Pandas dataframe containing rows 'source' and 'target' for the edges.\n",
    "          The 'source' value is always less than 'target'\n",
    "    \"\"\"\n",
    "    \n",
    "    ser_len = len(ser)\n",
    "    \n",
    "    # Return no edges for isolated codes\n",
    "    if ser_len <= 1:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    np_ary = ser.sort_values().to_numpy()\n",
    "    \n",
    "    # If we have a small list, np_list all\n",
    "    if ser_len <= min_n:\n",
    "        pairs = itertools.combinations(np_ary, 2)\n",
    "        return pd.DataFrame(pairs)\\\n",
    "           .set_axis(['source', 'target'], axis=1)\n",
    "\n",
    "    # Otherwise get samples.  Get the sources first\n",
    "    sources = np_ary.repeat(min_n).reshape((-1, 1))\n",
    "    \n",
    "    big_ser = (min_n*ser_len) >= big_thresh\n",
    "    \n",
    "    # If we have a very big series, just sample once. \n",
    "    if big_ser:\n",
    "        targets = np.random.choice(np_ary,  min_n*ser_len, replace=True) \\\n",
    "            .reshape((-1, 1))\n",
    "    else:\n",
    "        # For a medium sized series, sample more carefully\n",
    "        # Sample from nodes other than the source\n",
    "        targets = np.concatenate([np.random.choice(np.concatenate((np_ary[:i], np_ary[i+1:])), \n",
    "                                               min_n, replace=False) \\\n",
    "                                  for i in range(ser_len)]) \\\n",
    "            .reshape((-1, 1))\n",
    "    \n",
    "    # Combine sources and targets\n",
    "    comb_data = np.concatenate((sources, targets), axis=1)\n",
    "\n",
    "    # Sort, remove duplicates\n",
    "    comb_data.sort(axis=1)\n",
    "    samples = pd.DataFrame(comb_data, columns=['source', 'target']) \\\n",
    "        .drop_duplicates()\n",
    "    \n",
    "    # Remove self loops\n",
    "    if big_ser:\n",
    "        samples = samples[samples['target'] != samples['source']]\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de14c2-f702-436d-a681-25e8f3048ce8",
   "metadata": {},
   "source": [
    "## Edge Lists\n",
    "Create edge lists for the full dataset, as well as train + validation only.  Also do both sector and single-code lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2371481-ebdf-4746-8d14-d1b098b0013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get edges of both types\n",
    "def get_edges(data):\n",
    "    \n",
    "    # NAICS first\n",
    "    edges_all = pd.concat([pd.concat([get_sample_per_code(g.LoanNr_ChkDgt) \\\n",
    "                                          for n, g in data.groupby('NAICS_orig')], axis=0),\n",
    "                          pd.concat([get_sample_per_code(g.LoanNr_ChkDgt) \\\n",
    "                                          for n, g in data.groupby('NAICS_sector')], axis=0)],\n",
    "                          axis=0, keys=['naics', 'sector']) \\\n",
    "        .reset_index(level=0) \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .rename(columns={'level_0':'type'}, errors='ignore') \n",
    "    return edges_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ff3af-7b84-4190-9e3f-ebf98605e248",
   "metadata": {},
   "source": [
    "##### Edges - all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b56ec95b-7326-40c3-928d-f5bf56f7a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_all = get_edges(comb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "339b4896-f3fd-4f38-850e-522e437dced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_all.to_parquet(Path(setup.temp_path).joinpath('20_DATA_edges_naics_all.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e081a19-7e60-46ce-ae08-8af6c3a4254d",
   "metadata": {},
   "source": [
    "##### Edges - train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c662c317-f69c-46cc-8fec-e55ecff14152",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_train_val = get_edges(comb_df[comb_df['dset'].isin(['val', 'train'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9366a885-5fd7-4e27-8dd3-a15375e7b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_train_val.to_parquet(Path(setup.temp_path).joinpath('20_DATA_edges_naics_train_val.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339f73f-3f40-40b9-9f58-081e9dc86892",
   "metadata": {},
   "source": [
    "## Node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11c829d8-3db5-4b5d-805c-b3cb1d0bef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data_all = comb_df[['LoanNr_ChkDgt', 'dset'] + num_feat] \\\n",
    "    .set_index('LoanNr_ChkDgt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ee195-2cfd-42c8-ab13-26109306d521",
   "metadata": {},
   "source": [
    "## Create Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c795a02c-4629-410f-b236-32fe5747e3c0",
   "metadata": {},
   "source": [
    "##### All nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5abd508-ef54-4fd9-ba1e-692763d22c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sba_graph_all = StellarGraph({'LoanNr_ChkDgt':features_data_all.drop(columns=['dset'])},\n",
    "                             edges_all,\n",
    "                             source_column=\"source\", target_column=\"target\",\n",
    "                             edge_type_column=\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e72776-c6d2-418a-ac45-46efc06f3366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 688081, Edges: 66553913\n",
      "\n",
      " Node types:\n",
      "  LoanNr_ChkDgt: [688081]\n",
      "    Features: float32 vector, length 10\n",
      "    Edge types: LoanNr_ChkDgt-naics->LoanNr_ChkDgt, LoanNr_ChkDgt-sector->LoanNr_ChkDgt\n",
      "\n",
      " Edge types:\n",
      "    LoanNr_ChkDgt-sector->LoanNr_ChkDgt: [34354688]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n",
      "    LoanNr_ChkDgt-naics->LoanNr_ChkDgt: [32199225]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(sba_graph_all.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "529c6f9d-8f42-44a0-88a7-5ada24c3389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stellargraph object\n",
    "with open(Path(setup.temp_path).joinpath('20_DATA_stellargraph_all.pkl'), 'wb') as fout:\n",
    "      pickle.dump(sba_graph_all, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7121f-b406-41c1-83f8-cc817d6c4389",
   "metadata": {},
   "source": [
    "##### Train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d5f7734-cc2d-491b-a93d-c9a30ead19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_train_val = features_data_all[features_data_all['dset'].isin(['val','train'])].drop(columns=['dset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b9dd473-c0f8-4b80-9f48-8580604642ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sba_graph_train_val = StellarGraph({'LoanNr_ChkDgt':feat_train_val},\n",
    "                             edges_train_val,\n",
    "                             source_column=\"source\", target_column=\"target\",\n",
    "                             edge_type_column=\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffc0df6d-189d-4d9a-95a5-c31fa2f74cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 551635, Edges: 53101575\n",
      "\n",
      " Node types:\n",
      "  LoanNr_ChkDgt: [551635]\n",
      "    Features: float32 vector, length 10\n",
      "    Edge types: LoanNr_ChkDgt-naics->LoanNr_ChkDgt, LoanNr_ChkDgt-sector->LoanNr_ChkDgt\n",
      "\n",
      " Edge types:\n",
      "    LoanNr_ChkDgt-sector->LoanNr_ChkDgt: [27532592]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n",
      "    LoanNr_ChkDgt-naics->LoanNr_ChkDgt: [25568983]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(sba_graph_train_val.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "585ea8d7-aad9-4653-a4a1-81d45f05d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stellargraph object\n",
    "with open(Path(setup.temp_path).joinpath('20_DATA_stellargraph_train_val.pkl'), 'wb') as fout:\n",
    "      pickle.dump(sba_graph_train_val, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d13ca6-b70a-45d0-b062-a91763b371f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0dccbed-7f90-4f2c-a5d6-12b5b613ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = comb_df[['dset', 'dset_naics_holdout', 'LoanNr_ChkDgt', 'target']].set_index('LoanNr_ChkDgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14bbaa49-a447-435c-b911-4c5e84378ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.to_parquet(Path(setup.temp_path).joinpath('20_DATA_label_info.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b993beb1-990e-4e87-b0fa-76e01ee8ef82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_p39",
   "language": "python",
   "name": "tf_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
